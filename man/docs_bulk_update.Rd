% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/docs_bulk_update.R
\name{docs_bulk_update}
\alias{docs_bulk_update}
\title{Use the bulk API to update documents}
\usage{
docs_bulk_update(
  conn,
  x,
  index = NULL,
  type = NULL,
  chunk_size = 1000,
  doc_ids = NULL,
  raw = FALSE,
  quiet = FALSE,
  query = list(),
  digits = NA,
  sf = NULL,
  ...
)
}
\arguments{
\item{conn}{an Elasticsearch connection object, see \code{\link[=connect]{connect()}}}

\item{x}{A list, data.frame, or character path to a file. required.}

\item{index}{(character) The index name to use. Required for data.frame
input, but optional for file inputs.}

\item{type}{(character) The type. default: \code{NULL}. Note that \code{type} is
deprecated in Elasticsearch v7 and greater, and removed in Elasticsearch v8}

\item{chunk_size}{(integer) Size of each chunk. If your data.frame is smaller
thank \code{chunk_size}, this parameter is essentially ignored. We write in
chunks because at some point, depending on size of each document, and
Elasticsearch setup, writing a very large number of documents in one go
becomes slow, so chunking can help. This parameter is ignored if you
pass a file name. Default: 1000}

\item{doc_ids}{An optional vector (character or numeric/integer) of document
ids to use. This vector has to equal the size of the documents you are
passing in, and will error if not. If you pass a factor we convert to
character. Default: not passed}

\item{raw}{(logical) Get raw JSON back or not. If \code{TRUE}
you get JSON; if \code{FALSE} you get a list. Default: \code{FALSE}}

\item{quiet}{(logical) Suppress progress bar. Default: \code{FALSE}}

\item{query}{(list) a named list of query parameters. optional.
options include: pipeline, refresh, routing, _source, _source_excludes,
_source_includes, timeout, wait_for_active_shards. See the docs bulk
ES page for details}

\item{digits}{digits used by the parameter of the same name by
\code{\link[jsonlite:fromJSON]{jsonlite::toJSON()}} to convert data to JSON before being submitted to
your ES instance. default: \code{NA}}

\item{sf}{used by \code{\link[jsonlite:fromJSON]{jsonlite::toJSON()}} to convert sf objects.
Set to "features" for conversion to GeoJSON. default: "dataframe"}

\item{...}{Pass on curl options to \link[crul:HttpClient]{crul::HttpClient}}
}
\description{
Use the bulk API to update documents
}
\details{
\itemize{
\item \code{doc_as_upsert} - is set to \code{TRUE} for all records
}

For doing updates with a file already prepared for the bulk API,
see \code{\link[=docs_bulk]{docs_bulk()}}

Only data.frame's are supported for now.
}
\examples{
\dontrun{
x <- connect()
if (index_exists(x, "foobar")) index_delete(x, "foobar")

df <- data.frame(name = letters[1:3], size = 1:3, id = 100:102)
invisible(docs_bulk(x, df, 'foobar', es_ids = FALSE))

# add new rows in existing fields
(df2 <- data.frame(size = c(45, 56), id = 100:101))
(df2 <- data.frame(size = c(45, 56)))
df2$`_id` <- 100:101
df2
Search(x, "foobar", asdf = TRUE)$hits$hits
invisible(docs_bulk_update(x, df2, index = 'foobar'))
Search(x, "foobar", asdf = TRUE)$hits$hits

# add new fields (and new rows by extension)
(df3 <- data.frame(color = c("blue", "red", "green"), id = 100:102))
Search(x, "foobar", asdf = TRUE)$hits$hits
invisible(docs_bulk_update(x, df3, index = 'foobar'))
Sys.sleep(2) # wait for a few sec to make sure you see changes reflected
Search(x, "foobar", asdf = TRUE)$hits$hits
}
}
\references{
\url{https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html#bulk-update}
}
\seealso{
Other bulk-functions: 
\code{\link{docs_bulk_create}()},
\code{\link{docs_bulk_delete}()},
\code{\link{docs_bulk_index}()},
\code{\link{docs_bulk_prep}()},
\code{\link{docs_bulk}()}
}
\concept{bulk-functions}
